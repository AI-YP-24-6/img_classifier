# Baseline Model Documentation

## Введение
В данном документе описываются базовые модели, использованные для решения задачи классификации фруктов и овощей на изображении. Целью является создание начального бейзлайна для дальнейшего улучшения моделей и позволяющий оценивать их эффективность на данном этапе.

## Способы получения признаков:
Для получения признаков и подготовки данных для использования в моделях машинного обучения мы использовали следующие методы преобразования изображений:
- SIFT
- HOG
- ResNet18

## Модели
Для классификации фруктов и овощей мы использовали следующие модели:
- Метод опорных векторов (SVC)
- Логистическая линейная регрессия (LogReg)
- Деревья решений (Decision tree)

## Описание моделей

### 1. Метод опорных векторов (SVC)
- **Параметры модели по дефолту:** [C=1.0, kernel='rbf']
- **Обоснование выбора:** SVC выбрана благодаря своей точности при работе с большим количество изображений. Есть возможность использования различных ядер (линейное, полиномиальное, RBF),что позволяет адаптировать модель под разнообразные структуры данных и улучшать производительность. Стоит отметить, что из гиперпараметров изменяли только С и kernel.

### 2. Логистическая линейная регрессия
- **Обоснование выбора:** Высокая скорость обучения и хорошая интерпретируемость результатов.

### 3. Деревья решений
- **Параметры модели по дефолту:** [criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1]
- **Обоснование выбора:** Хорошая интерпритируемость результатов, чтобы посмотреть какие признаки влияют на классификацию. Ну и конечно просто интересно посмотреть, как справится с классификацией изображений нашего датасета.

## Выбор метрик
Для оценки качества моделей были выбраны следующие метрики:
- **Точность (Accuracy):** Доля правильно классифицированных изображений. Позволила нам получить общее представление о том, насколько хорошо работает модель.

При помощи функции sklearn.metrics.classification_report посмотрели следующие метрики:
- **Precision**, **Recall**, **F1-мера** - позволили оценить, как хорошо модель распознает каждый класс, и выявить классы, для которых модель работает плохо.
- **F1 Macro Average** - посмотрели как модель работает в среднем по всем классам. Так как у нас классы сбалансированы, то эта метрика практически не отличается от **Accuracy**

## Результаты
### 1. Выделение признаков с помощью SIFT:
- **Ссылка на ноутбук**: [Baseline_SIFT](./baseline_SIFT.ipynb)

| Модель         | Гиперпараметры                                                                    | Размер изображения | Цветное | accuracy на тесте | accuracy на трейне |
|----------------|-----------------------------------------------------------------------------------|--------------------|---------|---------------|----------------|
| SVC            | c = 8\.1, kernel = rbf                                                            | 64px               | чб      | 0,704         | 0\.87                |
| SVC            | c = 8\.1, kernel = rbf                                                            | 64px               | цветное | 0\.76         | 0\.88          |
| SVC            | c = 7\.1, kernel = rbf                                                            | 128px              | чб      | 0\.76         | 0\.86          |
| SVC            | c =8\.1 kernel = rbf                                                              | 128px              | цветное | 0\.79         | 0\.88          |
| LogReg         | c = 9\.1                                                                          | 64px               | чб      | 0\.47         | 0\.49          |
| LogReg         | с = 8\.1                                                                          | 64px               | цветное | 0\.54         | 0\.55          |
| LogReg         | c = 9\.1                                                                          | 128px              | чб      | 0\.56         | 0\.57          |
| LogReg         | c = 9\.1                                                                          | 128px              | цветное | 0\.57         | 0\.58          |
| DecisionTree | min\_samples\_split=20, min\_samples\_leaf=10, max\_depth=5, criterion= 'entropy' | 128px              | чб      | 0\.25         | 0\.25          |

**Выводы:**

Изображения:
- Увеличение размера изображений с 64px до 128px приводит к улучшению метрик, так как SIFT позволяет выделить больше уникальных признаков.(а не усреднять признаки при их недостаточном количестве)
- Использование цветных изображений также позволяет выявить больше признаков и как следствие улучшить метрики.

Выбор модели:
- Наилучшие результаты дает модель SVC. Но вместе с тем заметно больше уходит времени на обучение модели по сравнению с логистической регрессией.
- Логистическая регрессия показывает низкие метрики, но для базовой модели может вполне подойти, если поиграться гиперпараметрами, либо как вариант использовать другие способы извлечения признаков из изображений.
- Модель дерево решений не подходит от слова совсем, что и стоило ожидать. Очень низкие метрики

### 2. Выделение признаков с помощью HOG:
- **Ссылка на ноутбук**: [Baseline_HOG](./baseline_HOG.ipynb)

|Модель|Гиперпараметры|Размер изображения|Цветное|HOG ориентация|HOG пикселей в клетке|HOG клеток в блоке|accuracy на тесте| accuracy на трейне|
|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
|SVC|C=10, kernel='rbf'|64px|**да**|3|10,10|2,2|0.85|0.97|
|SVC+PCA|C=10, kernel='rbf', n_components=0.6|64px|**да**|3|10,10|2,2|0.72|0.78|
|SVC+PCA|C=10, kernel='rbf', n_components=0.4|64px|**да**|9|8,8|2,2|0.75|0.82|
|SVC|C=10, kernel='rbf'|128px|**да**|3|12,12|10,10|0.89|0.99|
|SVC+PCA|C=10, kernel='rbf', n_components=0.4|128px|**да**|3|12,12|10,10|0.60|0.62|
|LogReg + PCA|C=1|128px|нет|9|8,8|2,2|0.59|0.68|
|DecisionTree + PCA|min_samples_split=2, min_samples_leaf=1, max_depth=20, criterion='gini'|128px|нет|9|8,8|2,2|0.49|0.87|

**Выводы:**
Изображения:
- Увеличение размера изображений с 64px до 128px привело к улучшению метрик (особенно без PCA), но стало затрачивать больше вычислительных ресурсов
-  Использование цветных изображений показало себя лучше, чем черно-белых

Выбор модели:
- Лучше всего показала себя SVC, но относительно других моделей долго обучалась
- Модели показали переобучение - чем больше признаков, тем сильнее переобучение.
- PCA помогла уменьшить размерность признаков, из-за чего модель стала обучаться и предсказывать значительно быстрее, но это не сильно спасло от переобучения и понизило метрики

Параметры HOG
- Ориентации (orientations): оптимально взять значения от 3 до 9, значения выше не показывают улучшений
- Пиксели в клетке (pixels per cell): значения (8, 8) - (12, 12) показали лучший результат
- Клетки в блоке (cells per block): лучше всего показали себя значения (2, 2) и (10, 10). Стабильнее ведет себя (2, 2), т.к. (10, 10) вызвало сильное переобучение

Лучше всего использовать изображения 64x64px цветные, т.к. показывает неплохие метрики, обучается быстрее, чем на 128x128px.

### 3. Выделение признаков с помощью ResNet18:
- **Ссылка на ноутбук**: [Baseline_ResNet18](./baseline_ResNet18.ipynb)

|Модель|Гиперпараметры|Размер изображения|Цветное|accuracy на трейне|accuracy на тесте|
|:----:|:----:|:----:|:----:|:----:|:----:|
|SVC|C=12, kernel='rbf'|224px|да|1.0|0.98|
|SVC|C=10, kernel='rbf'|128px|да|1.0|0.96|
|SVC|C=18, kernel='rbf'|64px|да|1.0|0.94|
|LogisticRegression|C=0.1|224px|да|0.99|0.96|
|LogisticRegression|C=0.1|128px|да|0.97|0.93|
|LogisticRegression|C=0.1|64px|да|0.95|0.89|

**Выводы:**

Изображения:
- Большие изображения (224px) лучше подходят для извлечения информативных признаков, обеспечивая более высокую точность.
- Увеличение разрешения изображений существенно повышает время, необходимое для извлечения признаков и обучения модели. Например, обработка изображений размером 224px требует около часа, тогда как для 64px — лишь 15 минут.

Выбор модели:
- модели, основанные на SVC, продемонстрировали наивысшую точность на тестовой выборке, достигая 0.98
- Для Logistic Regression: точность снизилась с 0.96 (224px) до 0.89 (64px)

Таким образом, выбор оптимального размера изображения зависит от доступных ресурсов и требований к скорости обработки.


## Заключение
- Наилучшим решением для классификации изображений фруктов и овощей в качестве базовой модели стоит использовать метод опорных векторов (SVC), предварительно использовав метод понижения размерности датасета (PCA). Таким образом, время обучения модели существенно сокращается и практически соизмеримо с логистической регрессией. При этом показатели метрик выше.
- Для извлечения признаков из изображений наилучшим методом является HOG, если балансировать между скоростью извлечения признаков и точностью модели. Использование методов извлечения признаков ResNet18 - занимает довольно много времени от 30 до 60 минут. SIFT при использовании PCA показал плохие метрики, этот метод необходимо использовать с фиксированным числом признаков, но тогда мы теряем время на обучение модели - до 20 минут.
- Размер изображений стоит выбрать 64px - так достигается оптимальный баланс между скоростью и качеством модели

**Ноутбук с итоговой baseline моделью:** [Baseline](./baseline.ipynb)
