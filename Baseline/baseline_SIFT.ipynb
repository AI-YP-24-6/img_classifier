{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrgPhR6R_wvj"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)"
   ],
   "metadata": {
    "id": "sCnCA7JAIJdS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "file_id = \"1EbvcZbzVXSmB2N1SZYNeUfUuXb8wp3-k\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"dataset.zip\", quiet=False)\n",
    "\n",
    "zip_file_name = \"dataset.zip\"\n",
    "os.makedirs(\"dataset\", exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_name, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647UiuURIMIY",
    "outputId": "0094284a-b3ad-4164-8c33-474ea0f511d8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1EbvcZbzVXSmB2N1SZYNeUfUuXb8wp3-k\n",
      "From (redirected): https://drive.google.com/uc?id=1EbvcZbzVXSmB2N1SZYNeUfUuXb8wp3-k&confirm=t&uuid=1ca57790-9764-4c45-bb7c-5a47b993b9eb\n",
      "To: /content/dataset.zip\n",
      "100%|██████████| 652M/652M [00:04<00:00, 146MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "DATASET_DIR = \"./dataset\"\n",
    "TEMP_DATASET_DIR = \"./temp_dataset\"\n",
    "SIZE_IMG = {\"64px\": 64, \"100px\": 100, \"128px\": 128, \"192px\": 192}"
   ],
   "metadata": {
    "id": "NK2eMnTGImtH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_SIFT_descriptors(img):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    return descriptors"
   ],
   "metadata": {
    "id": "BVZHTCMUKCQZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделаем ограничение на количество дискрипторов в 128 шт. По опыту других ниболее оптимальный выбор. И так как в картинках может встретиться разное количество признаков, то выполним преобразование:\n",
    "\n",
    "\n",
    "*   Если количество дескрипторов меньше num_features, функция вычисляет среднее значение всех дескрипторов и присваивает его вектору признако\n",
    "*   Если количество дескрипторов больше или равно num_features, функция берет только первые num_features дескрипторов и вычисляет их среднее значение\n"
   ],
   "metadata": {
    "id": "CA383s9JK_Zz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def create_feature_vector(descriptors, num_features=128):\n",
    "    feature_vector = np.zeros(num_features)\n",
    "\n",
    "    if descriptors is not None and len(descriptors) > 0:\n",
    "        if descriptors.shape[0] < num_features:\n",
    "            feature_vector = np.mean(descriptors, axis=0)\n",
    "        else:\n",
    "            feature_vector = np.mean(descriptors[:num_features], axis=0)\n",
    "\n",
    "    return feature_vector"
   ],
   "metadata": {
    "id": "czLEp9PwK4N3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция предназначена для перебора всех картинок с датасета, преобразования их к типу SIFT и получения дискрипторов и названий классов."
   ],
   "metadata": {
    "id": "SZfS6MsjM-Z6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def analyze_dataset(image_folder, size_img):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in os.listdir(image_folder):\n",
    "        class_path = os.path.join(image_folder, class_name)\n",
    "\n",
    "        if os.path.isdir(class_path):\n",
    "            for filename in tqdm(os.listdir(class_path), desc=f\"Обработка {class_name}\", unit=\"image\"):\n",
    "                if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "                    image_path = os.path.join(class_path, filename)\n",
    "                    img = cv2.imread(image_path)\n",
    "                    img = cv2.resize(img, (size_img, size_img), interpolation=cv2.INTER_CUBIC)\n",
    "                    descriptors = get_SIFT_descriptors(img)\n",
    "\n",
    "                    feature_vector = create_feature_vector(descriptors)\n",
    "                    features.append(feature_vector)\n",
    "                    labels.append(class_name)\n",
    "\n",
    "    features_array = np.array(features)\n",
    "    labels_array = np.array(labels)\n",
    "\n",
    "    return features_array, labels_array"
   ],
   "metadata": {
    "id": "VVzddA-3MqRu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так как датасет довольно большой и модели обучаются долго, для тестирования и выбора наиболее подходящей модели имеет смысл сократить датасет. Я его помещу в отдельную папку temp_dataset. Изначально было 1400 изображений каждого класса, сокращу их до 500.\n"
   ],
   "metadata": {
    "id": "l0vcbXMMMdHs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def reduce_dataset(source_dir, temp_dir, num_images):\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_folder = os.path.join(source_dir, class_name)\n",
    "\n",
    "        if os.path.isdir(class_folder):\n",
    "            target_class_folder = os.path.join(temp_dir, class_name)\n",
    "            os.makedirs(target_class_folder, exist_ok=True)\n",
    "\n",
    "            all_images = os.listdir(class_folder)\n",
    "\n",
    "            selected_images = random.sample(all_images, min(num_images, len(all_images)))\n",
    "\n",
    "            for image in selected_images:\n",
    "                shutil.copy(os.path.join(class_folder, image), os.path.join(target_class_folder, image))\n",
    "\n",
    "            print(f\"Скопировано {len(selected_images)} изображений для класса {class_name} в {target_class_folder}\")"
   ],
   "metadata": {
    "id": "6gi2HsgAayFf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -r temp_dataset"
   ],
   "metadata": {
    "id": "nDpqCcOosFjQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "reduce_dataset(DATASET_DIR, TEMP_DATASET_DIR, 500)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0D7U690bIMn",
    "outputId": "e65d00e9-75c3-4b61-fd5e-0af07a076dc2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Скопировано 500 изображений для класса Pumpkin в ./temp_dataset/Pumpkin\n",
      "Скопировано 500 изображений для класса Nut в ./temp_dataset/Nut\n",
      "Скопировано 500 изображений для класса Apple в ./temp_dataset/Apple\n",
      "Скопировано 500 изображений для класса Cauliflower в ./temp_dataset/Cauliflower\n",
      "Скопировано 500 изображений для класса Bottle_Gourd в ./temp_dataset/Bottle_Gourd\n",
      "Скопировано 500 изображений для класса Pepper в ./temp_dataset/Pepper\n",
      "Скопировано 500 изображений для класса Peach в ./temp_dataset/Peach\n",
      "Скопировано 500 изображений для класса Mango в ./temp_dataset/Mango\n",
      "Скопировано 500 изображений для класса Stawberries в ./temp_dataset/Stawberries\n",
      "Скопировано 500 изображений для класса Brinjal в ./temp_dataset/Brinjal\n",
      "Скопировано 500 изображений для класса Bitter_Gourd в ./temp_dataset/Bitter_Gourd\n",
      "Скопировано 500 изображений для класса Radish в ./temp_dataset/Radish\n",
      "Скопировано 500 изображений для класса Potato в ./temp_dataset/Potato\n",
      "Скопировано 500 изображений для класса Cucumber в ./temp_dataset/Cucumber\n",
      "Скопировано 500 изображений для класса Avocado в ./temp_dataset/Avocado\n",
      "Скопировано 500 изображений для класса Pinenapple в ./temp_dataset/Pinenapple\n",
      "Скопировано 500 изображений для класса Banana в ./temp_dataset/Banana\n",
      "Скопировано 500 изображений для класса Carrot в ./temp_dataset/Carrot\n",
      "Скопировано 500 изображений для класса Pear в ./temp_dataset/Pear\n",
      "Скопировано 500 изображений для класса Plum в ./temp_dataset/Plum\n",
      "Скопировано 500 изображений для класса Capsicum в ./temp_dataset/Capsicum\n",
      "Скопировано 500 изображений для класса Grape в ./temp_dataset/Grape\n",
      "Скопировано 500 изображений для класса Cherry в ./temp_dataset/Cherry\n",
      "Скопировано 500 изображений для класса Orange в ./temp_dataset/Orange\n",
      "Скопировано 500 изображений для класса Bean в ./temp_dataset/Bean\n",
      "Скопировано 500 изображений для класса Cabbage в ./temp_dataset/Cabbage\n",
      "Скопировано 500 изображений для класса Strawberry в ./temp_dataset/Strawberry\n",
      "Скопировано 500 изображений для класса Broccoli в ./temp_dataset/Broccoli\n",
      "Скопировано 500 изображений для класса Onion в ./temp_dataset/Onion\n",
      "Скопировано 500 изображений для класса Tomato в ./temp_dataset/Tomato\n",
      "Скопировано 500 изображений для класса Watermelon в ./temp_dataset/Watermelon\n",
      "Скопировано 500 изображений для класса Papaya в ./temp_dataset/Papaya\n",
      "Скопировано 500 изображений для класса Kiwi в ./temp_dataset/Kiwi\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сильного улучшения не увидел, только метрики прям плохие, поэтому отказываюсь от этой идеи. Буду обучать на полном датасете. Анализ проводил в IDE, там все это дело быстрее. Буду благодарен если научить в colabe ускорять этот процесс"
   ],
   "metadata": {
    "id": "L-7QDNa4Sg9b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Визуализация признаков на изображениях\n",
    "Проведу анализ поиска признаков на цветных и чб изображениях и сделаю предположения, как влияет размер и цвет на выделение признаков\n",
    "\n"
   ],
   "metadata": {
    "id": "SC6mCIwrC0IP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# функция для получения признаков по всем каналам изображения RGB\n",
    "def color_sift(img):\n",
    "    channels = cv2.split(img)\n",
    "    keypoints_all = []\n",
    "    descriptors_all = []\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    for channel in channels:\n",
    "        keypoints, descriptors = sift.detectAndCompute(channel, None)\n",
    "        keypoints_all.extend(keypoints)\n",
    "        if descriptors is not None:\n",
    "            descriptors_all.append(descriptors)\n",
    "\n",
    "    if descriptors_all:\n",
    "        descriptors_combined = np.vstack(descriptors_all)\n",
    "    else:\n",
    "        descriptors_combined = None\n",
    "\n",
    "    return keypoints_all, descriptors_combined"
   ],
   "metadata": {
    "id": "MuPtHepEHipj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def show_sift_img(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_64 = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "    img_100 = cv2.resize(img, (100, 100), interpolation=cv2.INTER_CUBIC)\n",
    "    img_128 = cv2.resize(img, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints_rgb, descriptors_rgb = color_sift(img)\n",
    "    keypoints_gray, descriptors_gray = sift.detectAndCompute(img_gray, None)\n",
    "    keypoints_64, descriptors_gray_64 = sift.detectAndCompute(img_64, None)\n",
    "    keypoints_100, descriptors_gray_100 = sift.detectAndCompute(img_100, None)\n",
    "    keypoints_128, descriptors_gray_128 = sift.detectAndCompute(img_128, None)\n",
    "\n",
    "    sift_image_rgb = cv2.drawKeypoints(img, keypoints_rgb, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    sift_image_gray = cv2.drawKeypoints(\n",
    "        img_gray, keypoints_gray, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "    )\n",
    "    sift_image_64 = cv2.drawKeypoints(img_64, keypoints_64, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    sift_image_100 = cv2.drawKeypoints(img_100, keypoints_100, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    sift_image_128 = cv2.drawKeypoints(img_128, keypoints_128, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 6, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"исходник\")\n",
    "\n",
    "    plt.subplot(1, 6, 2)\n",
    "    plt.imshow(cv2.cvtColor(sift_image_rgb, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"в цвете\")\n",
    "\n",
    "    plt.subplot(1, 6, 3)\n",
    "    plt.imshow(sift_image_gray, cmap=\"gray\")\n",
    "    plt.title(\"в ЧБ\")\n",
    "\n",
    "    plt.subplot(1, 6, 4)\n",
    "    plt.imshow(cv2.cvtColor(sift_image_64, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"64px\")\n",
    "\n",
    "    plt.subplot(1, 6, 5)\n",
    "    plt.imshow(cv2.cvtColor(sift_image_100, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"100px\")\n",
    "\n",
    "    plt.subplot(1, 6, 6)\n",
    "    plt.imshow(cv2.cvtColor(sift_image_128, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"128px\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "Y4ZpRQQ58tF6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for class_name in os.listdir(DATASET_DIR):\n",
    "    class_path = os.path.join(DATASET_DIR, class_name)\n",
    "    img_name = random.sample(os.listdir(class_path), 1)[0]\n",
    "    img_path = os.path.join(DATASET_DIR, class_name, img_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    show_sift_img(img)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NuiT_lG69Z1S",
    "outputId": "dcb227ee-2d84-423c-edb3-8c8e4f6bc3b5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Визуальное представление показало, что признаков в черно-белом формате меньше, чем в цветном. Разница незначительная, но для повышения точности модели будем обучаться на цветных изображениях. Для хорошей точности лучше использовать изображения в цвете, но есть риск переобучения моделли. Поэтому если будет возникать переобучения, то попробую испозовать чб размером 128px.\n",
    "P.S. на представленных выше картинках, где указаны размеры, поиск признаков тоже проводился на чб изображении, вывод сделал в цвете (SIFT внутри всегда преобразует в чб и ищет признаки)"
   ],
   "metadata": {
    "id": "BCga2kHYG7-N"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение моделей\n",
    "\n",
    "*   Получим дескрипторы с каждого изображения и названия классов исходя из преположений сделанных раннее\n",
    "*   Разобьем выборку на трейн и тест\n",
    "*  Подберем гиперпараметры для моделей LinearRegression и SVC c помощью гридсерча\n",
    "*   Посмотрим метрики на различных модельках\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "J122h832JlzU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "descriptors, labels = analyze_dataset(DATASET_DIR, 128)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(descriptors), labels, test_size=0.20, random_state=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBGJ-81CJRfY",
    "outputId": "052370d8-1658-4eae-bc1a-c5a9776bbfc0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Обработка Pumpkin: 100%|██████████| 500/500 [00:02<00:00, 214.11image/s]\n",
      "Обработка Nut: 100%|██████████| 500/500 [00:01<00:00, 414.77image/s]\n",
      "Обработка Apple: 100%|██████████| 500/500 [00:01<00:00, 301.44image/s]\n",
      "Обработка Cauliflower: 100%|██████████| 500/500 [00:05<00:00, 92.83image/s]\n",
      "Обработка Bottle_Gourd: 100%|██████████| 500/500 [00:02<00:00, 191.39image/s]\n",
      "Обработка Pepper: 100%|██████████| 500/500 [00:01<00:00, 345.62image/s]\n",
      "Обработка Peach: 100%|██████████| 500/500 [00:01<00:00, 350.23image/s]\n",
      "Обработка Mango: 100%|██████████| 500/500 [00:02<00:00, 186.93image/s]\n",
      "Обработка Stawberries: 100%|██████████| 500/500 [00:07<00:00, 69.54image/s] \n",
      "Обработка Brinjal: 100%|██████████| 500/500 [00:03<00:00, 143.23image/s]\n",
      "Обработка Bitter_Gourd: 100%|██████████| 500/500 [00:02<00:00, 198.92image/s]\n",
      "Обработка Radish: 100%|██████████| 500/500 [00:02<00:00, 249.42image/s]\n",
      "Обработка Potato: 100%|██████████| 500/500 [00:01<00:00, 254.72image/s]\n",
      "Обработка Cucumber: 100%|██████████| 500/500 [00:03<00:00, 127.77image/s]\n",
      "Обработка Avocado: 100%|██████████| 500/500 [00:01<00:00, 282.84image/s]\n",
      "Обработка Pinenapple: 100%|██████████| 500/500 [00:01<00:00, 261.19image/s]\n",
      "Обработка Banana: 100%|██████████| 500/500 [00:01<00:00, 280.31image/s]\n",
      "Обработка Carrot: 100%|██████████| 500/500 [00:02<00:00, 230.09image/s]\n",
      "Обработка Pear: 100%|██████████| 500/500 [00:01<00:00, 346.11image/s]\n",
      "Обработка Plum: 100%|██████████| 500/500 [00:02<00:00, 225.62image/s]\n",
      "Обработка Capsicum: 100%|██████████| 500/500 [00:03<00:00, 133.00image/s]\n",
      "Обработка Grape: 100%|██████████| 500/500 [00:01<00:00, 389.62image/s]\n",
      "Обработка Cherry: 100%|██████████| 500/500 [00:01<00:00, 274.35image/s]\n",
      "Обработка Orange: 100%|██████████| 500/500 [00:01<00:00, 307.10image/s]\n",
      "Обработка Bean: 100%|██████████| 500/500 [00:02<00:00, 212.77image/s]\n",
      "Обработка Cabbage: 100%|██████████| 500/500 [00:02<00:00, 227.57image/s]\n",
      "Обработка Strawberry: 100%|██████████| 500/500 [00:03<00:00, 128.59image/s]\n",
      "Обработка Broccoli: 100%|██████████| 500/500 [00:03<00:00, 161.28image/s]\n",
      "Обработка Onion: 100%|██████████| 500/500 [00:03<00:00, 151.26image/s]\n",
      "Обработка Tomato: 100%|██████████| 500/500 [00:03<00:00, 152.83image/s]\n",
      "Обработка Watermelon: 100%|██████████| 500/500 [00:03<00:00, 136.04image/s]\n",
      "Обработка Papaya: 100%|██████████| 500/500 [00:02<00:00, 168.44image/s]\n",
      "Обработка Kiwi: 100%|██████████| 500/500 [00:02<00:00, 243.58image/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функции для обучения различных моделей и просмотра метрик\n",
    "1. **SVC модель** - выбор обоснован ее точностью при работе с изображениями, хоть она и медленная. С помощью gridSearch подберу оптимальное ядро и параметр c\n",
    "2. **LogisticRegression** - выбор обоснован скоростью ее работы на больших данных и возможность посмотреть вероятность правильного предсказания. Также подберу оптимальный параметр с\n",
    "3. **Decision Trees** - более чем уверен, что результат будет плох, но для интереса посмотреть можно\n"
   ],
   "metadata": {
    "id": "fgeX5UpHTMjI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def SVC_model(X_train, X_test, y_train, y_test, c_parametr, type_kernel):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    pipeline = Pipeline([(\"scaler\", MinMaxScaler()), (\"svc\", SVC(C=c_parametr, kernel=type_kernel))])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test, average=\"weighted\")\n",
    "    print(\"SVC TEST:\")\n",
    "    print(f\"Accuracy: {accuracy_test:.6f}\")\n",
    "    print(f\"F1 Score: {f1_test:.6f}\")\n",
    "\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train, average=\"weighted\")\n",
    "    print(\"SVC TRAIN:\")\n",
    "    print(f\"Accuracy: {accuracy_train:.6f}\")\n",
    "    print(f\"F1 Score: {f1_train:.6f}\")\n",
    "\n",
    "    # print(\"SVC TRAIN:\")\n",
    "    # print(classification_report(y_train, y_pred_train))\n",
    "    # print(\"SVC TEST:\")\n",
    "    # print(classification_report(y_test, y_pred_test))"
   ],
   "metadata": {
    "id": "9J7vJmqdSozH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def LogReg_model(X_train, X_test, y_train, y_test, c_parametr):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", MinMaxScaler()),\n",
    "            (\"log_reg\", LogisticRegression(C=c_parametr, solver=\"lbfgs\", max_iter=500)),\n",
    "        ]\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test, average=\"weighted\")\n",
    "    print(\"LogReg Performance TEST:\")\n",
    "    print(f\"Accuracy: {accuracy_test:.6f}\")\n",
    "    print(f\"F1 Score: {f1_test:.6f}\")\n",
    "\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train, average=\"weighted\")\n",
    "    print(\"LogReg Performance TRAIN:\")\n",
    "    print(f\"Accuracy: {accuracy_train:.6f}\")\n",
    "    print(f\"F1 Score: {f1_train:.6f}\")\n",
    "\n",
    "    # print(\"LogReg TRAIN:\")\n",
    "    # print(classification_report(y_train, y_pred_train))\n",
    "    # print(\"LogReg TEST:\")\n",
    "    # print(classification_report(y_test, y_pred_test))"
   ],
   "metadata": {
    "id": "n2g1dBxN9wCM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def DT_model(X_train, X_test, y_train, y_test, param):\n",
    "    # param = {\n",
    "    #     'criterion': 'entropy',\n",
    "    #     'max_depth': 5,\n",
    "    #     'min_samples_split': 20,\n",
    "    #     'min_samples_leaf': 10\n",
    "    # }\n",
    "\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    dt_model.set_params(**param)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = dt_model.predict(X_test)\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test, average=\"weighted\")\n",
    "    print(\"Decision Trees TEST:\")\n",
    "    print(f\"Accuracy: {accuracy_test:.6f}\")\n",
    "    print(f\"F1 Score: {f1_test:.6f}\")\n",
    "\n",
    "    y_pred_train = dt_model.predict(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train, average=\"weighted\")\n",
    "    print(\"Decision Trees TRAIN:\")\n",
    "    print(f\"Accuracy: {accuracy_train:.6f}\")\n",
    "    print(f\"F1 Score: {f1_train:.6f}\")"
   ],
   "metadata": {
    "id": "SRkmMsJVUl6-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# поиск лучших гиперпараметров у опорных векторов\n",
    "def get_best_param_svc(X_train, y_train):\n",
    "    param_grid = {\n",
    "        \"svc__C\": np.arange(0.1, 10, 1),\n",
    "        \"svc__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    }\n",
    "    pipeline = Pipeline([(\"scaler\", MinMaxScaler()), (\"svc\", SVC())])\n",
    "    svс = RandomizedSearchCV(pipeline, param_grid, cv=3)\n",
    "    svс.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Лучшие параметры:\", svс.best_params_)\n",
    "    print(\"Лучшая оценка:\", svс.best_score_)\n",
    "    return svс.best_params_"
   ],
   "metadata": {
    "id": "KAju_JDUXg9A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# поиск лучших гиперпараметров у логистической регрессии\n",
    "def get_best_param_lr(X_train, y_train):\n",
    "    param_grid = {\"log_reg__C\": np.arange(0.1, 10, 1)}\n",
    "    pipeline = Pipeline([(\"scaler\", MinMaxScaler()), (\"log_reg\", LogisticRegression(solver=\"lbfgs\", max_iter=1000))])\n",
    "    log_reg = RandomizedSearchCV(pipeline, param_grid, cv=3)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Лучшие параметры:\", log_reg.best_params_)\n",
    "    print(\"Лучшая оценка:\", log_reg.best_score_)\n",
    "    return log_reg.best_params_"
   ],
   "metadata": {
    "id": "qX-2RZakb_qo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# поиск лучших гиперпараметров у дерева решений\n",
    "def get_best_param_dt(X_train, y_train):\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    param_grid = {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [5, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 10, 20],\n",
    "        \"min_samples_leaf\": [1, 5, 10],\n",
    "    }\n",
    "\n",
    "    dt = RandomizedSearchCV(dt_model, param_grid, cv=5, scoring=\"f1\", n_iter=10)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Лучшие параметры:\", dt.best_params_)\n",
    "    print(\"Лучшая оценка:\", dt.best_score_)\n",
    "    return dt.best_params_"
   ],
   "metadata": {
    "id": "Bk9jscP4XJoj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# посмотрим кросс валидацию на предмет качества модели линейной регрессии и метода опорных векторов\n",
    "scores_lr = []\n",
    "scores_svm = []\n",
    "\n",
    "for c in np.arange(0.1, 10, 1):\n",
    "    pipeline_lr = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", MinMaxScaler()),\n",
    "            (\"log_reg\", LogisticRegression(C=c, solver=\"lbfgs\", max_iter=500)),\n",
    "        ]\n",
    "    )\n",
    "    pipeline_svc = Pipeline([(\"scaler\", MinMaxScaler()), (\"svc\", SVC(C=c, kernel=\"rbf\"))])\n",
    "    pipeline_lr.fit(X_train, y_train)\n",
    "    pipeline_svc.fit(X_train, y_train)\n",
    "\n",
    "    pred_lr = pipeline_lr.predict(X_test)\n",
    "    pred_svc = pipeline_svc.predict(X_test)\n",
    "\n",
    "    scores_lr.append(\n",
    "        {\n",
    "            \"acc\": accuracy_score(y_test, pred_lr),\n",
    "            \"f1\": f1_score(y_test, pred_lr, average=\"weighted\"),\n",
    "        }\n",
    "    )\n",
    "    scores_svm.append(\n",
    "        {\n",
    "            \"acc\": accuracy_score(y_test, pred_svc),\n",
    "            \"f1\": f1_score(y_test, pred_svc, average=\"weighted\"),\n",
    "        }\n",
    "    )"
   ],
   "metadata": {
    "id": "pa64QE8Fl1fa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "scores_lr"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZucp5z1ozwa",
    "outputId": "d551207f-6643-44cc-97f3-c8370d7aa1cd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'acc': 0.30627705627705626, 'f1': 0.2633904564786971},\n",
       " {'acc': 0.39285714285714285, 'f1': 0.36747243816479375},\n",
       " {'acc': 0.41125541125541126, 'f1': 0.38757209876957754},\n",
       " {'acc': 0.4145021645021645, 'f1': 0.3924627704066258},\n",
       " {'acc': 0.41233766233766234, 'f1': 0.3922591099837431},\n",
       " {'acc': 0.41125541125541126, 'f1': 0.3920915565031611},\n",
       " {'acc': 0.408008658008658, 'f1': 0.3893902596518665},\n",
       " {'acc': 0.4101731601731602, 'f1': 0.39122998287420324},\n",
       " {'acc': 0.4069264069264069, 'f1': 0.3890214817561307},\n",
       " {'acc': 0.4036796536796537, 'f1': 0.3855299214991083}]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "scores_svm"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMjINi2Yo75y",
    "outputId": "9a6ddd8d-54df-42d2-f22d-379f9a3ff5de"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'acc': 0.20887445887445888, 'f1': 0.1575339366369778},\n",
       " {'acc': 0.4458874458874459, 'f1': 0.4208645687046207},\n",
       " {'acc': 0.4686147186147186, 'f1': 0.45021229778432326},\n",
       " {'acc': 0.4816017316017316, 'f1': 0.4630607715602206},\n",
       " {'acc': 0.48268398268398266, 'f1': 0.4677861925477941},\n",
       " {'acc': 0.4880952380952381, 'f1': 0.47564100898122563},\n",
       " {'acc': 0.4880952380952381, 'f1': 0.47805457445259075},\n",
       " {'acc': 0.49134199134199136, 'f1': 0.482104377990633},\n",
       " {'acc': 0.4902597402597403, 'f1': 0.48038728370045725},\n",
       " {'acc': 0.49134199134199136, 'f1': 0.4815526396576269}]"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "svc_param = get_best_param_svc(X_train, y_train)"
   ],
   "metadata": {
    "id": "cxcVjyp4rKLX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "SVC_model(X_train, X_test, y_train, y_test, svc_param[\"svc__C\"], svc_param[\"svc__kernel\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZuRBb-yKyuo",
    "outputId": "a8dffb24-9045-491e-d78c-981f81943590"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC TEST:\n",
      "Accuracy: 0.491342\n",
      "F1 Score: 0.481553\n",
      "SVC TRAIN:\n",
      "Accuracy: 0.961580\n",
      "F1 Score: 0.961776\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "lr_param = get_best_param_lr(X_train, y_train)"
   ],
   "metadata": {
    "id": "RsmSvgRkrUf7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "LogReg_model(X_train, X_test, y_train, y_test, lr_param[\"log_reg__C\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvlFM8K6FMIf",
    "outputId": "403bbdd1-0013-4605-b925-efcb8b4b4cde"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogReg Performance TEST:\n",
      "Accuracy: 0.410173\n",
      "F1 Score: 0.391230\n",
      "LogReg Performance TRAIN:\n",
      "Accuracy: 0.563582\n",
      "F1 Score: 0.550504\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dt_param = get_best_param_dt(X_train, y_train)"
   ],
   "metadata": {
    "id": "piHpDEl-rUm2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DT_model(X_train, X_test, y_train, y_test, dt_param)"
   ],
   "metadata": {
    "id": "nHPfCFQ_oO39"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Таблица результатов"
   ],
   "metadata": {
    "id": "kBWHlun7n3v7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Модель         | Гиперпараметры                                                                    | Размер изображения | Цветное | accuracy Test | accuracy Train | переобучение |   |   |   |\n",
    "|----------------|-----------------------------------------------------------------------------------|--------------------|---------|---------------|----------------|--------------|---|---|---|\n",
    "| SVC            | c = 8\\.1, kernel = rbf                                                            | 64px               | чб      | 0,704         | 0\\.87          | да           |   |   |   |\n",
    "| SVC            | c = 8\\.1, kernel = rbf                                                            | 64px               | цветное | 0\\.76         | 0\\.88          | меньше       |   |   |   |\n",
    "| SVC            | c = 7\\.1, kernel = rbf                                                            | 128px              | чб      | 0\\.76         | 0\\.86          | думаю нет    |   |   |   |\n",
    "| SVC            | c =8\\.1 kernel = rbf                                                              | 128px              | цветное | 0\\.79         | 0\\.88          | думаю нет    |   |   |   |\n",
    "| LogReg         | c = 9\\.1                                                                          | 64px               | чб      | 0\\.47         | 0\\.49          | нет          |   |   |   |\n",
    "| LogReg         | с = 8\\.1                                                                          | 64px               | цветное | 0\\.54         | 0\\.55          | нет          |   |   |   |\n",
    "| LogReg         | c = 9\\.1                                                                          | 128px              | чб      | 0\\.56         | 0\\.57          | нет          |   |   |   |\n",
    "| LogReg         | c = 9\\.1                                                                          | 128px              | цветное | 0\\.57         | 0\\.58          | нет          |   |   |   |\n",
    "| Decision Trees | min\\_samples\\_split=20, min\\_samples\\_leaf=10, max\\_depth=5, criterion= 'entropy' | 128px              | чб      | 0\\.25         | 0\\.25          | нет          |   |   |   |\n"
   ],
   "metadata": {
    "id": "ewRUVOUfmV8O"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Выводы:\n",
    "\n",
    "1.   Наилучшие результаты дает модель SVC с гиперпараметрами c=8.1 kernel=rbf,размер изображения 128px, цветное\n",
    "2.   Для ускорения можно использовать модель в оттенках серого с гиперпараметрами с=7.1, kernel=8.1, размер 128px\n",
    "3.   Логистическая регрессия не совсем подходит для данного датасета, модель должна быть сложнее\n",
    "4. Модель дерево решений не подходит от слова совсем, что и стоило ожидать\n",
    "\n",
    "P.S.\n",
    "\n",
    "*   Обучение моделей проводилось только после подбора наилучших гиперпараметров методом RandomizedSearchCV\n",
    "*   Для оценки качества модели использовалась метрика accuracy, так как легко интерпритируема и дает хорошее качество на сбаллансированных классах, а они у нас такие. Также смотрел f1 метрику, хотя она и применяется больше для несбалансированных классов, но тем не менее дает неплохую точность.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "II4R6vLOmeEW"
   }
  }
 ]
}
