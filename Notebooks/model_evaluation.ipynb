{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-15T10:09:17.760978Z",
     "iopub.status.idle": "2025-06-15T10:09:17.761164Z",
     "shell.execute_reply": "2025-06-15T10:09:17.761079Z",
     "shell.execute_reply.started": "2025-06-15T10:09:17.761071Z"
    }
   },
   "source": [
    "%% md\n",
    "# Оценка модели на наборе данных Art Goskatalog\n",
    "\n",
    "Это\n",
    "тестирование\n",
    "ноутбука\n",
    "все\n",
    "`.pth\n",
    "` и `.pt\n",
    "` модели\n",
    "веса, найденные\n",
    "в\n",
    "`.. / DLModels\n",
    "` каталог\n",
    "на\n",
    "наборе\n",
    "данных\n",
    "изображения, расположенный\n",
    "в\n",
    "`.. / Notebooks / goskatalog_art_final\n",
    "`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip\n",
    "install\n",
    "ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:13:11.738388Z",
     "iopub.status.busy": "2025-06-15T10:13:11.737876Z",
     "iopub.status.idle": "2025-06-15T10:13:11.743514Z",
     "shell.execute_reply": "2025-06-15T10:13:11.743514Z",
     "shell.execute_reply.started": "2025-06-15T10:13:11.738388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:13:11.743514Z",
     "iopub.status.busy": "2025-06-15T10:13:11.743514Z",
     "iopub.status.idle": "2025-06-15T10:13:11.753524Z",
     "shell.execute_reply": "2025-06-15T10:13:11.753524Z",
     "shell.execute_reply.started": "2025-06-15T10:13:11.743514Z"
    }
   },
   "source": [
    "# Оценка модели на наборе данных Art Goskatalog\n",
    "\n",
    "Это\n",
    "тестирование\n",
    "ноутбука\n",
    "все\n",
    "`.pth\n",
    "` и `.pt\n",
    "` модели\n",
    "веса, найденные\n",
    "в\n",
    "`.. / DLModels\n",
    "` каталог\n",
    "на\n",
    "наборе\n",
    "данных\n",
    "изображения, расположенный\n",
    "в\n",
    "`.. / Notebooks / goskatalog_art_final\n",
    "`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-15T10:09:17.762913Z",
     "iopub.status.idle": "2025-06-15T10:09:17.763203Z",
     "shell.execute_reply": "2025-06-15T10:09:17.763104Z",
     "shell.execute_reply.started": "2025-06-15T10:09:17.763095Z"
    }
   },
   "source": [
    "pip\n",
    "install\n",
    "ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:13:11.848067Z",
     "iopub.status.busy": "2025-06-15T10:13:11.848067Z",
     "iopub.status.idle": "2025-06-15T10:13:11.866332Z",
     "shell.execute_reply": "2025-06-15T10:13:11.866332Z",
     "shell.execute_reply.started": "2025-06-15T10:13:11.848067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in directory: ..\\Notebooks\\goskatalog_art_final\n",
      "Found image files: 1255\n",
      "Loaded 1255 images for testing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define paths\n",
    "models_dir = os.path.join(\"..\", \"DLModels\")\n",
    "data_dir = os.path.join(\"..\", \"Notebooks\", \"goskatalog_art_final\")\n",
    "\n",
    "# Find all model weight files\n",
    "model_paths = glob.glob(os.path.join(models_dir, \"*.pth\")) + glob.glob(os.path.join(models_dir, \"*.pt\"))\n",
    "\n",
    "print(f\"Found {len(model_paths)} model weights:\")\n",
    "for path in model_paths:\n",
    "    print(os.path.basename(path))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:13:12.202186Z",
     "iopub.status.busy": "2025-06-15T10:13:12.202186Z",
     "iopub.status.idle": "2025-06-15T10:13:18.592843Z",
     "shell.execute_reply": "2025-06-15T10:13:18.592067Z",
     "shell.execute_reply.started": "2025-06-15T10:13:12.202186Z"
    }
   },
   "source": "## 1. Загрузка данных и подготовка"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Custom dataset for loading images from a directory.\"\"\"\n",
    "\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        # List image files and check for debugging\n",
    "        self.image_files = [\n",
    "            os.path.join(directory, dirs, f)\n",
    "            for dirs in os.listdir(directory)\n",
    "            for f in os.listdir(os.path.join(directory, dirs))\n",
    "            if f.lower().endswith((\"png\", \"jpg\", \"jpeg\", \"bmp\", \"gif\", \"tif\"))\n",
    "        ]\n",
    "        print(f\"Searching in directory: {directory}\")\n",
    "        print(f\"Found image files: {len(self.image_files)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except (IOError, OSError) as e:\n",
    "            print(f\"Could not read image {img_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# Transformations for standard ImageNet models (ResNet, EfficientNet)\n",
    "imagenet_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create dataset and dataloader for classification models\n",
    "full_dataset = ImageDataset(data_dir, transform=imagenet_transform)\n",
    "data_loader = DataLoader(full_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Get all image paths for YOLO\n",
    "all_image_paths = [\n",
    "    (os.path.join(data_dir, dirs, f), dirs)\n",
    "    for dirs in os.listdir(data_dir)\n",
    "    for f in os.listdir(os.path.join(data_dir, dirs))\n",
    "    if f.lower().endswith((\"png\", \"jpg\", \"jpeg\"))\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(full_dataset)} images for testing.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Модель и вывод"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 5,
   "source": [
    "def show_results(images, titles):\n",
    "    \"\"\"Helper function to display images with titles.\"\"\"\n",
    "    num_images = len(images)\n",
    "    # Create a figure with a flexible number of subplots\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(5 * num_images, 5))\n",
    "    if num_images == 1:  # If there's only one image, axes is not a list\n",
    "        axes = [axes]\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i])\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for model_path in model_paths:\n",
    "    model_name = os.path.basename(model_path)\n",
    "    print(f\"\\n--- Testing {model_name} ---\")\n",
    "\n",
    "    try:\n",
    "        model = None\n",
    "        is_yolo = False\n",
    "\n",
    "        if \"resnet50\" in model_name.lower():\n",
    "            print(\"Loading ResNet50 architecture...\")\n",
    "            model = torchvision.models.resnet50(weights=None)  # Load without pre-trained weights\n",
    "            # The error indicates the saved model has 32 output classes\n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = torch.nn.Linear(num_ftrs, 32)\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            loader = data_loader\n",
    "\n",
    "        elif \"efficientnet\" in model_name.lower():\n",
    "            print(\"Loading EfficientNet_B0 architecture...\")\n",
    "            model = torchvision.models.efficientnet_b0(weights=None)  # Load without pre-trained weights\n",
    "            # The error indicates the saved model has 256 output classes\n",
    "            num_ftrs = model.classifier[1].in_features\n",
    "            model.classifier[1] = torch.nn.Linear(num_ftrs, 256)\n",
    "            # Use strict=False to ignore non-matching keys like 'classifier.3...' etc.\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "            loader = data_loader\n",
    "\n",
    "        elif \"yolo\" in model_name.lower():\n",
    "            print(\"Loading YOLO model...\")\n",
    "            is_yolo = True\n",
    "            model = YOLO(model_path)\n",
    "\n",
    "        else:\n",
    "            print(f\"Unknown model architecture for {model_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if not is_yolo:\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "\n",
    "        print(\"Running inference on a sample batch...\")\n",
    "        with torch.no_grad():\n",
    "            if is_yolo:\n",
    "                # For YOLO, we pass a list of image paths directly\n",
    "                sample_paths = random.sample(all_image_paths, min(4, len(all_image_paths)))\n",
    "                ans = []\n",
    "                path_ = []\n",
    "                for pa, class_ in sample_paths:\n",
    "                    ans.append(class_)\n",
    "                    path_.append(pa)\n",
    "                sample_paths = path_\n",
    "                results = model(sample_paths, verbose=False)\n",
    "                for i, _ in enumerate(results):\n",
    "                    if ans[i] == results[i].to_df().iloc[0, 0]:\n",
    "                        ans[i] += \"=True\"\n",
    "                    else:\n",
    "                        ans[i] += \"=False\"\n",
    "                plotted_images = [r.plot() for r in results]  # .plot() returns a BGR numpy array\n",
    "                # Convert BGR to RGB for matplotlib\n",
    "                plotted_images_rgb = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in plotted_images]\n",
    "                titles = [f\"YOLO Prediction {i+1}\" for i in range(len(results))]\n",
    "                show_results(plotted_images_rgb, ans)\n",
    "            else:\n",
    "                # For classification models, use the data loader\n",
    "                tensor_batch = next(iter(loader))\n",
    "                if tensor_batch is None:\n",
    "                    print(\"Could not load a batch of images. Skipping model.\")\n",
    "                    continue\n",
    "\n",
    "                outputs = model(tensor_batch.to(device))\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                titles = [f\"Predicted Class Index: {p.item()}\" for p in preds]\n",
    "\n",
    "                # Un-normalize images for display\n",
    "                display_images = []\n",
    "                for img_tensor in tensor_batch:\n",
    "                    img_tensor = img_tensor.cpu().numpy().transpose((1, 2, 0))\n",
    "                    mean = np.array([0.485, 0.456, 0.406])\n",
    "                    std = np.array([0.229, 0.224, 0.225])\n",
    "                    img_tensor = std * img_tensor + mean\n",
    "                    img_tensor = np.clip(img_tensor, 0, 1)\n",
    "                    display_images.append(img_tensor)\n",
    "                show_results(display_images, titles)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while testing {model_name}: {e}\")\n",
    "\n",
    "print(\"\\n--- All models tested. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aikernel",
   "language": "python",
   "name": "aikernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
