---
hide:
  - navigation
---

# Сводные результаты ML-моделей

## Краткое описание
- В данном документе подведены итоги экспериментов по классификации изображений с использованием признаков HOG и SIFT.
- Проведено сравнение эффективности различных моделей машинного обучения.
- HOG в сочетании с CatBoost показал наилучший результат, достигнув точности **79%**.
- Эксперимент с `VotingClassifier` не привел к улучшению метрик по сравнению с лучшей одиночной моделью.

## Содержание
- [Результаты на основе HOG](#результаты-на-основе-hog)
- [Результаты на основе SIFT](#результаты-на-основе-sift)
- [Эксперимент с VotingClassifier](#эксперимент-с-votingclassifier)
- [Итоговые выводы](#итоговые-выводы)

## Результаты на основе HOG
*Цель*: Оценка моделей на признаках, описывающих градиенты и форму объектов.

|Модель|Гиперпараметры|accuracy|f1-macro|
|:----:|:----:|:----:|:----:|
|SVC+PCA|n_components=0.6, C=10, kernel='rbf'|0.76|0.76|
|RandomForest+PCA|n_components=0.6, ...|0.77|0.77|
|LightGBM+PCA|n_components=0.6, ...|0.78|0.78|
|**CatBoost+PCA**|**n_components=0.6, depth=10, ...**|**0.79**|**0.79**|

!!! success "Лучшая модель"
    CatBoost с PCA (n_components=0.6) и настроенными гиперпараметрами показал наивысшую точность **79%**.

[Подробнее об экспериментах с HOG...](HOG_experimets_2.md)

## Результаты на основе SIFT
*Цель*: Оценка моделей на признаках, описывающих ключевые точки на изображении.

| Модель | Гиперпараметры | accuracy | f1-macro |
|:---|:---|:---:|:---:|
| RandomForest | n_estimators: 200, ... | 0.65 | 0.65 |
| **LightGBM** | **min_child_samples: 66, ...** | **0.71** | **0.71** |
| CatBoost | depth: 10, ... | 0.70 | 0.70 |

!!! info "Вывод"
    Признаки SIFT (с упрощенной агрегацией) оказались менее эффективными. Лучший результат показал LightGBM с точностью **71%**.

[Подробнее об экспериментах с SIFT...](SIFT_experiments.md)

## Эксперимент с VotingClassifier
*Цель*: Объединить лучшие модели на HOG (CatBoost) и SIFT (LightGBM) для потенциального улучшения результата.

**Результат**:
- **Accuracy**: 0.76
- **F1-macro**: 0.75

!!! warning "Результат не улучшился"
    Ансамбль показал результат ниже, чем лучшая модель на HOG. Вероятно, более слабая модель на SIFT-признаках внесла шум и ухудшила общую производительность.

[Подробнее об ансамбле...](ML_voting_model.md)

## Итоговые выводы
1.  **HOG > SIFT**: Для данной задачи классификации изображений дескриптор HOG оказался значительно более эффективным, чем SIFT с упрощенной агрегацией.
2.  **Эффективность бустинга**: Модели градиентного бустинга (`CatBoost` и `LightGBM`) стабильно показывали лучшие результаты по сравнению с `SVC` и `RandomForest`.
3.  **Польза PCA**: Применение метода главных компонент (PCA) для сокращения размерности HOG-признаков позволило ускорить обучение и, возможно, избежать переобучения, не жертвуя качеством.
4.  **Лучшая конфигурация**: Связка **HOG + PCA + CatBoost** является оптимальным решением, обеспечившим точность **79%**.
